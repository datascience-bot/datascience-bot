# TODO: Find a way to shorten build time.
#   Unfortunately, travis cannot cache docker images. ¯\_(ツ)_/¯
#   Consider deploying image to dockerhub (only when it changes),
#   and pulling the image with each build.
#   https://stackoverflow.com/questions/35305492/cache-docker-images-on-travis-ci
#   https://docs.docker.com/registry/recipes/mirror/
#   https://github.com/travis-ci/travis-ci/issues/5358
# Reduce memory usage to avoid docker 137 (out-of-memory) errors
#   https://docs.bazel.build/versions/2.2.0/memory-saving-mode.html
# Docker Flags Explained
#   Keep the docker container running throughout the build.
#     --detach --interactive --tty
#   Keep memory usage in check
#     --memory=1g --memory-swap=10g --oom-kill-disable
# Why skip_cleanup: true everywhere?
#   Travis runs `git stash --all` when skip_cleanup: false.
#   This action stashes everything in the _output dir and creates a ton of log messages.
#   So many log messages, in fact, that travis build fail:
#   e.g. The job exceeded the maximum log length, and has been terminated.
services: docker
env:
  global:
    - ENV_FILE=.env
    - IMAGE_TAG=datascience-bot/dev
    - CONTAINER_NAME=my-container
    - IMAGE_WORKDIR=/workspaces/datascience-bot
    - DOCKER_RUN_FLAGS="--memory=1g --memory-swap=10g --oom-kill-disable --detach --interactive --tty --env-file=${ENV_FILE} --volume=$(pwd):${IMAGE_WORKDIR} --workdir=${IMAGE_WORKDIR}"
before_install:
  - echo "DATASCIENCE_BOT_USERNAME=${DATASCIENCE_BOT_USERNAME}" >> ${ENV_FILE}
  - echo "DATASCIENCE_BOT_PASSWORD=${DATASCIENCE_BOT_PASSWORD}" >> ${ENV_FILE}
  - echo "DATASCIENCE_BOT_CLIENT_ID=${DATASCIENCE_BOT_CLIENT_ID}" >> ${ENV_FILE}
  - echo "DATASCIENCE_BOT_CLIENT_SECRET=${DATASCIENCE_BOT_CLIENT_SECRET}" >> ${ENV_FILE}
  - echo "SUBREDDIT_NAME=${SUBREDDIT_NAME}" >> ${ENV_FILE}
  - echo "SUBSTANTIALSTRAIN6_USERNAME=${SUBSTANTIALSTRAIN6_USERNAME}" >> ${ENV_FILE}
  - echo "SUBSTANTIALSTRAIN6_PASSWORD=${SUBSTANTIALSTRAIN6_PASSWORD}" >> ${ENV_FILE}
  - echo "SUBSTANTIALSTRAIN6_CLIENT_ID=${SUBSTANTIALSTRAIN6_CLIENT_ID}" >> ${ENV_FILE}
  - echo "SUBSTANTIALSTRAIN6_CLIENT_SECRET=${SUBSTANTIALSTRAIN6_CLIENT_SECRET}" >> ${ENV_FILE}
  - echo "B3405920_USERNAME=${B3405920_USERNAME}" >> ${ENV_FILE}
  - echo "B3405920_PASSWORD=${B3405920_PASSWORD}" >> ${ENV_FILE}
  - echo "B3405920_CLIENT_ID=${B3405920_CLIENT_ID}" >> ${ENV_FILE}
  - echo "B3405920_CLIENT_SECRET=${B3405920_CLIENT_SECRET}" >> ${ENV_FILE}
  - docker build -t ${IMAGE_TAG} .
  - docker run ${DOCKER_RUN_FLAGS} --name=${CONTAINER_NAME} ${IMAGE_TAG}
before_script:
  - ls -a
script:
  - docker exec ${CONTAINER_NAME} /bin/bash -c "bazel build //..."
  - docker exec ${CONTAINER_NAME} /bin/bash -c "bazel test //... --jobs=1"
  - docker exec ${CONTAINER_NAME} /bin/bash -c "bash get-build-artifacts.sh"
deploy:
  # deploy subreddit settings to r/datascience_bot_dev
  - provider: script
    script: docker exec ${CONTAINER_NAME} /bin/bash -c "bazel run //apps/modtools/site_admin:bin datascience_bot_dev"
    skip_cleanup: true  # avoid super long logs
    on:
      branch: master
  # deploy subreddit settings to r/datascience
  - provider: script
    script: docker exec ${CONTAINER_NAME} /bin/bash -c "bazel run //apps/modtools/site_admin:bin datascience"
    skip_cleanup: true  # avoid super long logs
    on:
      tags: true
  # deploy removal reasons to r/datascience_bot_dev
  - provider: script
    script: docker exec ${CONTAINER_NAME} /bin/bash -c "bazel run //apps/modtools/removal_reasons:bin datascience_bot_dev"
    skip_cleanup: true  # avoid super long logs
    on:
      branch: master
  # deploy removal reasons to r/datascience
  - provider: script
    script: docker exec ${CONTAINER_NAME} /bin/bash -c "bazel run //apps/modtools/removal_reasons:bin datascience"
    skip_cleanup: true  # avoid super long logs
    on:
      tags: true
  # deploy wiki to r/datascience_bot_dev
  - provider: script
    script: docker exec ${CONTAINER_NAME} /bin/bash -c "bazel run //apps/wiki:bin datascience_bot_dev"
    skip_cleanup: true  # avoid super long logs
    on:
      branch: master
  # deploy wiki to r/datascience
  - provider: script
    script: docker exec ${CONTAINER_NAME} /bin/bash -c "bazel run //apps/wiki:bin datascience"
    skip_cleanup: true  # avoid super long logs
    on:
      tags: true
  # deploy submission moderator app
  - provider: lambda
    region: us-east-1
    role: arn:aws:iam::491984534845:role/datascience-bot-travis-ci
    runtime: python3.7
    function_name: datascience-bot-submission-moderator
    module_name: lambda_function
    handler_name: lambda_handler
    timeout: 30
    zip: _output/submission_moderator_app/lambda_pkg.zip
    skip_cleanup: true  # avoid super long logs
    on:
      tags: true
  # deploy entering and transitioning app
  - provider: lambda
    region: us-east-1
    role: arn:aws:iam::491984534845:role/datascience-bot-travis-ci
    runtime: python3.7
    function_name: datascience-bot-entering-and-transitioning-app
    module_name: lambda_function
    handler_name: lambda_handler
    timeout: 300
    zip: _output/entering_and_transitioning_app/lambda_pkg.zip
    skip_cleanup: true  # avoid super long logs
    on:
      tags: true
